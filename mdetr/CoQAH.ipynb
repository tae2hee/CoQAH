{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38689c45-7903-4ac1-8fef-5be9da7f05a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import json\n",
    "import os\n",
    "import random\n",
    "import sys\n",
    "from functools import partial\n",
    "from pathlib import Path\n",
    "from typing import Dict, List\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.utils\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, DistributedSampler\n",
    "\n",
    "# PACKAGE_PARENT = \"..\"\n",
    "# SCRIPT_DIR = os.path.dirname(os.path.realpath(os.path.join(os.getcwd(), os.path.expanduser(__file__))))\n",
    "# sys.path.append(os.path.normpath(os.path.join(SCRIPT_DIR, PACKAGE_PARENT)))\n",
    "\n",
    "import main as detection\n",
    "import util.dist as dist\n",
    "import util.misc as utils\n",
    "from datasets import build_dataset\n",
    "from datasets.clevr import ALL_ATTRIBUTES\n",
    "from engine import evaluate\n",
    "from models import build_model\n",
    "from util.metrics import MetricLogger\n",
    "\n",
    "import datasets.transforms as T\n",
    "from PIL import Image\n",
    "from matplotlib import pyplot as plt\n",
    "from mpl_toolkits.axes_grid1 import ImageGrid\n",
    "\n",
    "from transformers import RobertaModel, RobertaTokenizerFast"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50696a87-c8cc-4583-81e5-252bc2e2cb92",
   "metadata": {},
   "source": [
    "## Settings for MDETR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4192ac6-3b69-4e1c-a224-0cd2a81e7859",
   "metadata": {},
   "outputs": [],
   "source": [
    "def local_get_args_parser():\n",
    "    detection_parser = detection.get_args_parser()\n",
    "    parser = argparse.ArgumentParser(\n",
    "        \"Get predictions for clevr and dump to file\", parents=[detection_parser], add_help=False\n",
    "    )\n",
    "    return parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4066eada-5874-4e41-b202-663e4c3ce7be",
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser(\n",
    "        \"Get predictions for CLEVR and dump to file\", parents=[local_get_args_parser()], add_help=False\n",
    "    )\n",
    "args = parser.parse_args(['--dataset_config', 'configs/clevr.json', '--resume', './clevr_checkpoint.pth'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47013132-cc90-414d-adc7-70ef2e36bd48",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalize = T.Compose([T.ToTensor(), T.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce018ee1-1b3e-4bc2-8423-0c2823709939",
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_sample(image, question):\n",
    "    image = normalize(image,\n",
    "                {\n",
    "                    \"boxes\": torch.zeros(0, 4),\n",
    "                    \"labels\": torch.zeros(0),\n",
    "                    \"iscrowd\": torch.zeros(0),\n",
    "                    \"positive_map\": torch.zeros(0),\n",
    "                },)[0].unsqueeze(0)\n",
    "    target = {\n",
    "            \"questionId\": question[\"question_index\"] if \"question_index\" in question else idx,\n",
    "            \"caption\": question[\"question\"],\n",
    "        }\n",
    "    captions = [target[\"caption\"]]\n",
    "    return image, captions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e40b80b8-4cf9-4e63-941d-7d6c1eeb3fed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def infer_mdetr(img, question, model):\n",
    "    sample = {\"question\": question}\n",
    "    samples, captions = construct_sample(img, sample)\n",
    "    samples = samples.to(device)\n",
    "    memory_cache = model(samples, captions, encode_and_save=True)\n",
    "    outputs = model(samples, captions, encode_and_save=False, memory_cache=memory_cache)\n",
    "    answers = []\n",
    "    answer_types = outputs[\"pred_answer_type\"].argmax(-1)\n",
    "    answer_types = [x.item() for x in answer_types]\n",
    "    for i, ans_type in enumerate(answer_types):\n",
    "        if ans_type == 0:\n",
    "            answers.append(\"yes\" if outputs[\"pred_answer_binary\"][i].sigmoid() > 0.5 else \"no\")\n",
    "        elif ans_type == 1:\n",
    "            answers.append(ALL_ATTRIBUTES[outputs[\"pred_answer_attr\"][i].argmax(-1).item()])\n",
    "        elif ans_type == 2:\n",
    "            answers.append(str(outputs[\"pred_answer_reg\"][i].argmax(-1).item()))\n",
    "        else:\n",
    "            assert False, \"must be one of the answer types\"\n",
    "    return answers[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f8140b6-9322-4ae5-a3ac-7eb65874838e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update dataset specific configs\n",
    "if args.dataset_config is not None:\n",
    "    # https://stackoverflow.com/a/16878364\n",
    "    d = vars(args)\n",
    "    with open(args.dataset_config, \"r\") as f:\n",
    "        cfg = json.load(f)\n",
    "    d.update(cfg)\n",
    "\n",
    "if args.mask_model != \"none\":\n",
    "    args.masks = True\n",
    "\n",
    "device = torch.device(args.device)\n",
    "seed = args.seed + dist.get_rank()\n",
    "torch.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)\n",
    "\n",
    "checkpoint = torch.load(args.resume, map_location=\"cpu\")\n",
    "\n",
    "model_args = checkpoint[\"args\"]\n",
    "model_args.device = args.device\n",
    "\n",
    "model_args.combine_datasets = [\"clevr_question\"]\n",
    "for a in vars(args):\n",
    "    if a not in vars(model_args):\n",
    "        vars(model_args)[a] = vars(args)[a]\n",
    "\n",
    "model, _, _, _, _ = build_model(model_args)\n",
    "if \"ema\" in args and args.ema:\n",
    "    assert \"model_ema\" in checkpoint\n",
    "    model.load_state_dict(checkpoint[\"model_ema\"])\n",
    "else:\n",
    "    model.load_state_dict(checkpoint[\"model\"], strict=False)\n",
    "model.to(device)\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1d43b38-4bb9-4077-902a-ceb5617f5a28",
   "metadata": {},
   "source": [
    "## Settings for ChatGPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4fcb698-bc10-4d09-88ba-b638ee1d7d0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic ChatGPT class\n",
    "import openai\n",
    "\n",
    "class BasicChatGPT:\n",
    "    def __init__(self, openai_api_key, max_tokens=100):\n",
    "        openai.api_key = openai_api_key\n",
    "        self.max_tokens = max_tokens\n",
    "        self.messages = []\n",
    "\n",
    "    def call(self):\n",
    "        response = openai.ChatCompletion.create(\n",
    "          model=\"gpt-4\",\n",
    "          messages=self.messages,\n",
    "          max_tokens=self.max_tokens,\n",
    "          seed = 123,\n",
    "        )\n",
    "        return response\n",
    "\n",
    "    def prompt(self, text):\n",
    "        # Update the messages so far\n",
    "        self.messages.append({\n",
    "            \"role\": \"user\",\n",
    "            \"content\": text,\n",
    "        })\n",
    "\n",
    "        # Call ChatGPT\n",
    "        response = self.call()\n",
    "\n",
    "        # Save the returned message\n",
    "        message = response[\"choices\"][0][\"message\"]\n",
    "        self.messages.append(message)\n",
    "\n",
    "        return message[\"content\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14a81235-5170-49af-92f7-552d956540a8",
   "metadata": {},
   "source": [
    "## Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "715828a7-1054-47e9-8b84-be89882c1a83",
   "metadata": {},
   "outputs": [],
   "source": [
    "ann = json.loads(open('CLEVR-Humans-val.json', 'r').read())\n",
    "image_path = \"CLEVR/CLEVR_v1.0/images/val/\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76a3cae7-a71a-4e4d-93a0-576892b4555e",
   "metadata": {},
   "source": [
    "## Functions for CoQAH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9e12137-43b6-4d03-81fe-8baa1a9ff77e",
   "metadata": {},
   "outputs": [],
   "source": [
    "STARTING_PROMPT = \"\"\" \n",
    "But you can't access the image and I can access the image.\n",
    "You can ask me questions with these forms.\n",
    "The question should be in []\n",
    "If you can answer the above question, stop asking and give me an answer within 1 word.\n",
    "The answer should be in {}\n",
    "[is there a <SIZE> <COLOR> <MATERIAL> <SHAPE> <RELATION> <SIZE> <COLOR> <MATERIAL> <SHAPE> ?]\n",
    "[what size is <SIZE> <COLOR> <MATERIAL> <SHAPE> <RELATION> <SIZE> <COLOR> <MATERIAL> <SHAPE> ?]\n",
    "[what color is <SIZE> <COLOR> <MATERIAL> <SHAPE> <RELATION> <SIZE> <COLOR> <MATERIAL> <SHAPE> ?]\n",
    "[what material is <SIZE> <COLOR> <MATERIAL> <SHAPE> <RELATION> <SIZE> <COLOR> <MATERIAL> <SHAPE> ?]\n",
    "[what shape is <SIZE> <COLOR> <MATERIAL> <SHAPE> <RELATION> <SIZE> <COLOR> <MATERIAL> <SHAPE> ?]\n",
    "[How many <SIZE> <COLOR> <MATERIAL> <SHAPE> <RELATION> <SIZE> <COLOR> <MATERIAL> <SHAPE> are there?]\n",
    "\n",
    "<SIZE> :  [<EMPTY> or small or large]\n",
    "<COLOR>:  [<EMPTY> or gray or red or blue or green or brown or purple or cyan or yellow]\n",
    "<MATERIAL>: [<EMPTY> or rubber or metal]\n",
    "<SHAPE>: [<EMPTY> or cube or sphere or cylinder or object]\n",
    "<RELATION>: [<EMPTY> or \"left of\" or \"right of\" or \"in front of\" or \"behind\"] \n",
    "<EMPTY>: Just let it empty.  At least one should be not <EMPTY>\n",
    "\n",
    "Ask me the next question after I answer you.\n",
    "Ask me questions carefully  considering existence and uniqueness presupposition.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc29bcd0-6937-4cd5-9ff4-31cec344a21c",
   "metadata": {},
   "outputs": [],
   "source": [
    "BRAKET_ERROR = \"The question should be in []\"\n",
    "FORMAT_ERROR = \"Unsupported format or unsupported option. choose the most similar option, even if itâ€™s not totally the same.\"\n",
    "EXISTENCE_ERROR = \"there is no \"\n",
    "UNIQUENESS_ERROR = \"there are \"\n",
    "EMPTY_ERROR = \"At least one should not be <EMPTY>\"\n",
    "\n",
    "SIZE = [\"small\", \"tiny\", \"large\", \"big\"]\n",
    "COLOR = [\"gray\", \"red\", \"blue\", \"green\", \"brown\", \"purple\", \"cyan\", \"yellow\"]\n",
    "MATERAIL = [\"rubber\", \"matte\", \"metal\", \"metallic\", \"shiny\"]\n",
    "SHAPE = [\"cube\", \"block\", \"sphere\", \"ball\", \"cylinder\", \"object\", \"thing\", \"cubes\", \"blocks\", \"spheres\", \"balls\", \"cylinders\", \"objects\", \"things\"]\n",
    "RELATION = [\"left\", \"right\", \"front\", \"behind\"]\n",
    "PREPOSITION = [\"in\", \"of\"]\n",
    "\n",
    "REMOVE_S = {\"cubes\": \"cube\", \"blocks\": \"block\", \"spheres\": \"sphere\", \"balls\": \"ball\", \"cylinders\": \"cylinder\", \"objects\": \"object\", \"things\": \"thing\"}\n",
    "SYNONYMS = {\"tiny\": \"small\", \"big\": \"large\", \"matte\": \"rubber\", \"metallic\": \"metal\", \"shiny\": \"metal\", \"block\": \"cube\", \"ball\": \"sphere\"}\n",
    "\n",
    "ANSWER_OPTIONS = [\"yes\", \"no\", \"small\", \"tiny\", \"large\", \"big\", \"gray\", \"red\", \"blue\", \"green\", \"brown\", \"purple\", \"cyan\", \"yellow\", \"rubber\", \"matte\", \"metal\", \"metallic\", \"shiny\", \"cube\", \"block\", \"sphere\", \"ball\", \"cylinder\", \"cubes\", \"blocks\", \"spheres\", \"balls\", \"cylinders\"]\n",
    "\n",
    "question_limit = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "291b8fd1-996f-469f-8597-629780a88dbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def post_process_answer(answer):\n",
    "    answer = answer.lower().replace(\".\",\"\")\n",
    "    if answer in REMOVE_S.keys():\n",
    "        answer = REMOVE_S[answer]\n",
    "    if answer in SYNONYMS.keys():\n",
    "        answer = SYNONYMS[answer]\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ed41d6b-f087-4e0a-a8f1-3f9fc9b5b741",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ask_why(chatgpt):\n",
    "    prompt = \"Why?\"\n",
    "    prompt = \"User: \" + prompt\n",
    "    response = chatgpt.prompt(prompt)\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43d8e67f-05e1-4ba0-bba3-2f79d88f9f04",
   "metadata": {},
   "outputs": [],
   "source": [
    "def guess_answer(chatgpt):\n",
    "    prompt = \"\"\"You have used all the chances to ask questions. Now, guess a answer anyway.\n",
    "    You can choose the answer in these options [\"yes\", \"no\", \"small\", \"tiny\", \"large\", \"big\", \"gray\", \"red\", \"blue\", \"green\", \"brown\", \"purple\", \"cyan\", \"yellow\", \"rubber\", \"matte\", \"metal\", \"metallic\", \"shiny\", \"cube\", \"block\", \"sphere\", \"ball\", \"cylinder\", \"cubes\", \"blocks\", \"spheres\", \"balls\", \"cylinders\"] or a digital number\n",
    "    Give me an answer within 1 word.\n",
    "    The answer should be in {}\n",
    "    \"\"\"\n",
    "    prompt = \"User: \" + prompt\n",
    "    response = chatgpt.prompt(prompt)\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a3348cf-0748-4f68-911f-34de987d6374",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_answer_format(answer, chatgpt):\n",
    "    if answer not in ANSWER_OPTIONS and not answer.isdigit():\n",
    "        prompt = \"\"\" You have to choose your answer in these options\n",
    "        [\"yes\", \"no\", \"small\", \"tiny\", \"large\", \"big\", \"gray\", \"red\", \"blue\", \"green\", \"brown\", \"purple\", \"cyan\", \"yellow\", \"rubber\", \"matte\", \"metal\", \"metallic\", \"shiny\", \"cube\", \"block\", \"sphere\", \"ball\", \"cylinder\", \"cubes\", \"blocks\", \"spheres\", \"balls\", \"cylinders\"] or a digital number\n",
    "        The answer should be in {}\n",
    "        \"\"\"\n",
    "        prompt = \"User: \" + prompt\n",
    "        response = chatgpt.prompt(prompt)\n",
    "        abidx = response.find('{')\n",
    "        aeidx = response.find('}')\n",
    "        if abidx != -1 or aeidx != -1:\n",
    "            response = response[abidx+1:aeidx]\n",
    "        return False, response\n",
    "    else:\n",
    "        return True, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4148559f-661b-4737-8f94-19854f5089e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_format(response):\n",
    "    entities = response.lower().replace(\"?\",\"\").replace(\" a \",\" \").replace(\" the \",\" \").replace(\"is there\",\"\").replace(\"what size is\",\"\").replace(\"what color is\",\"\").replace(\"what material is\",\"\").replace(\"what shape is\",\"\").replace(\"how many\",\"\").replace(\"are there\",\"\").replace(\"<empty>\",\"\").strip().split(\" \")\n",
    "    entity = \"\"\n",
    "    for e in entities:\n",
    "        if len(e) == 0 or e in PREPOSITION: continue\n",
    "        if (e not in SIZE) and (e not in COLOR) and (e not in MATERAIL) and (e not in SHAPE) and (e not in RELATION):\n",
    "            return False, entity , e\n",
    "        if e in REMOVE_S.keys():\n",
    "            e = REMOVE_S[e]\n",
    "        if e == \"left\" or e == \"right\":\n",
    "            e += \" of\"\n",
    "        if e == \"front\":\n",
    "            e = \"in front of\"\n",
    "        entity += e + \" \"\n",
    "    entity = entity.strip()\n",
    "    return True, entity, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acb177db-c8b5-4044-98d6-f5d1459f946e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_existence(entity):\n",
    "    ex_q = f\"is there a {entity}?\"\n",
    "    ex_a = infer_mdetr(img, ex_q, model)\n",
    "    if \"yes\" in ex_a:\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2e02789-3a49-45c0-8ddc-f986efcb7684",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_uniqueness(entity):\n",
    "    uq_q = f\"how many {entity} are there?\"\n",
    "    uq_a = infer_mdetr(img, uq_q, model)\n",
    "    try:\n",
    "        uq_a = int(uq_a)\n",
    "        return uq_a\n",
    "    except:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efdab528-d0c6-4249-9afd-bb2485b9918d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def handling_response(response, hist, rep):\n",
    "    abidx = response.find('{')\n",
    "    aeidx = response.find('}')\n",
    "    if abidx != -1 or aeidx != -1:\n",
    "        a_gpt = response[abidx+1:aeidx]\n",
    "        return True, a_gpt, \"DONE!\", hist\n",
    "    \n",
    "    qbidx = response.find('[')\n",
    "    qeidx = response.find(']')\n",
    "    if qbidx == -1 or qeidx == -1:\n",
    "        return False, None, BRAKET_ERROR, hist\n",
    "    q_gpt = response[qbidx+1:qeidx]\n",
    "    q_gpt = q_gpt.lower().replace(\"<empty>\",\"\")\n",
    "    q_gpt_nos = q_gpt.split()\n",
    "    q_gpt_nos = [REMOVE_S[e] if e in REMOVE_S.keys() else e for e in q_gpt_nos]\n",
    "    q_gpt_nos = ' '.join(q_gpt_nos)\n",
    "    correct_format, entity, unsup_e = check_format(q_gpt_nos)\n",
    "    if not correct_format:\n",
    "        return False, None, unsup_e + \": \" + FORMAT_ERROR, hist\n",
    "    if len(entity) == 0:\n",
    "        return False, None, EMPTY_ERROR, hist\n",
    "    hist[f\"E{str(rep)}\"] = entity\n",
    "    existence = check_existence(entity)\n",
    "    if not existence:\n",
    "        return False, None, EXISTENCE_ERROR + entity, hist\n",
    "    uniqueness = check_uniqueness(entity)\n",
    "    if uniqueness != 1:\n",
    "        return False, None, UNIQUENESS_ERROR + str(uniqueness) + \" \" + entity + \"s\", hist\n",
    "    \n",
    "    hist[f\"P{str(rep)}\"] = q_gpt\n",
    "    feedback = infer_mdetr(img, q_gpt, model)\n",
    "    \n",
    "    return False, None, feedback, hist\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e6e6f73-28a9-4a91-9152-49a9dbf61255",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chatgpt_dialogue(prompt):\n",
    "    memo = {\"history\": []}\n",
    "    openai_api_key = \"<YOUR_OPENAI_API_KEY>\"\n",
    "    chatgpt = BasicChatGPT(openai_api_key)\n",
    "    done = False\n",
    "    rep = 0 \n",
    "    while(not done and rep < question_limit):\n",
    "        hist = {}\n",
    "        prompt = \"User: \" + prompt\n",
    "        response = chatgpt.prompt(prompt)\n",
    "        hist[f\"Q{str(rep)}\"] = response\n",
    "        done, answer, prompt, hist = handling_response(response, hist, rep)\n",
    "        hist[f\"A{str(rep)}\"] = prompt\n",
    "        memo[\"history\"].append(hist)\n",
    "        rep += 1\n",
    "    if not done:\n",
    "        response = guess_answer(chatgpt)\n",
    "        done, answer, prompt, hist = handling_response(response, hist, rep)\n",
    "        memo[\"guess\"] = answer\n",
    "    memo[\"raw_answer\"] = answer\n",
    "    processed_answer = post_process_answer(answer)\n",
    "    memo[\"answer\"] = processed_answer\n",
    "    valid, re_answer = check_answer_format(processed_answer, chatgpt)\n",
    "    reason = ask_why(chatgpt)\n",
    "    memo[\"reason\"] = reason\n",
    "    if valid:\n",
    "        return processed_answer, memo\n",
    "    else:\n",
    "        memo[\"raw_re_answer\"] = re_answer\n",
    "        processed_re_answer = post_process_answer(re_answer)\n",
    "        memo[\"re_answer\"] = processed_re_answer\n",
    "        return processed_re_answer, memo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc9d4063-e1fc-40d0-9545-f46fd577ea54",
   "metadata": {},
   "source": [
    "## Run CoQAH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eedabd1f-79e5-4254-8cb4-f805bac7a765",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import time\n",
    "from sklearn.metrics import *\n",
    "import json\n",
    "\n",
    "save_file = 'coqah_20_clevr_human_val.json'\n",
    "base_save_file = save_file.replace('coqah','base')\n",
    "\n",
    "if os.path.isfile(save_file):\n",
    "    res_dict = json.loads(open(save_file, 'r').read())\n",
    "    base_dict = json.loads(open(base_save_file, 'r').read())\n",
    "    starting_idx = res_dict[\"id\"][-1]+1\n",
    "else:\n",
    "    res_dict = {\"id\": [], \"res\": [], \"gts\": [], \"memo\": []}\n",
    "    base_dict = {\"id\": [], \"res\": [], \"gts\": []}\n",
    "    starting_idx = 0\n",
    "    \n",
    "for idx in range(starting_idx, len(ann[\"questions\"])):\n",
    "    sample = ann[\"questions\"][idx]\n",
    "    file_name = sample[\"image_filename\"]\n",
    "    question = sample[\"question\"]\n",
    "    gt = sample[\"answer\"]\n",
    "    img = Image.open(os.path.join(image_path, file_name)).convert(\"RGB\")\n",
    "\n",
    "    qprompt = f\"Your goal is to answer this question:\\n{question}\\n\"\n",
    "    sprompt = qprompt + STARTING_PROMPT\n",
    "    try:\n",
    "        answer, memo = chatgpt_dialogue(sprompt)\n",
    "    except:\n",
    "        print(\"wating for time limit\")\n",
    "        time.sleep(60)\n",
    "        answer, memo = chatgpt_dialogue(sprompt)\n",
    "    \n",
    "    res_dict[\"id\"].append(idx)\n",
    "    res_dict[\"res\"].append(answer)\n",
    "    res_dict[\"gts\"].append(gt)\n",
    "    res_dict[\"memo\"].append(memo)\n",
    "    acc = accuracy_score(res_dict[\"gts\"], res_dict[\"res\"])\n",
    "    with open(save_file, 'w') as f:\n",
    "        json.dump(res_dict, f)\n",
    "    print(idx)\n",
    "    print(\"gt: \", gt)\n",
    "    print(\"pred: \", answer)\n",
    "    print(\"AFA ACC: \",acc)\n",
    "    baseline_answer = infer_mdetr(img, question, model)\n",
    "    base_dict[\"id\"].append(idx)\n",
    "    base_dict[\"res\"].append(baseline_answer)\n",
    "    base_dict[\"gts\"].append(gt)\n",
    "    base_acc = accuracy_score(base_dict[\"gts\"], base_dict[\"res\"])\n",
    "    with open(base_save_file, 'w') as f:\n",
    "        json.dump(base_dict, f)\n",
    "    print(\"Baseline: \", baseline_answer)\n",
    "    print(\"Baseline ACC: \", base_acc)\n",
    "    time.sleep(1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mdetr_env",
   "language": "python",
   "name": "mdetr_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
